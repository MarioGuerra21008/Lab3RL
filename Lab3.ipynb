{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75f95bc",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingenier√≠a - Computaci√≥n</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -20px\">\n",
    "        <strong>Curso:</strong> CC3104 - Aprendizaje por Refuerzo \n",
    "        <strong>Secci√≥n:</strong> 10\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Laboratorio 3:</strong> MDP</p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autores:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hern√°ndez Silvestre - <strong>21270</strong></li>\n",
    "        <li>Linda In√©s Jim√©nez Vides - <strong>21169</strong></li>\n",
    "        <li>Mario Antonio Guerra Morales - <strong>21008</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efa3ce",
   "metadata": {},
   "source": [
    "## üìù Task 1\n",
    "Responda a cada de las siguientes preguntas de forma clara y lo m√°s completamente posible.\n",
    "1. ¬øQu√© es Programaci√≥n Din√°mica y c√≥mo se relaciona con RL?\n",
    "\n",
    "- \n",
    "\n",
    "2. Explique en sus propias palabras el algoritmo de Iteraci√≥n de P√≥liza.\n",
    "\n",
    "- \n",
    "\n",
    "3. Explique en sus propias palabras el algoritmo de Iteraci√≥n de Valor.\n",
    "\n",
    "- \n",
    "\n",
    "4. En el laboratorio pasado, vimos que el valor de los premios obtenidos se mantienen constantes, ¬øpor qu√©?"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAALMAAACnCAIAAADVMfopAAAI3ElEQVR4Ae2dXWwUVRTH74tBLBqiDTFk1SAofiQg8DYvJr4gWKO0WLsFdB+a+2qiKGoENNsYE15uilqzilqxoCbGj4eJmgK2LkQU1BgQNkNod6tQaqxtAcGP5Jjpdj0n7Z3YHZqUmfn3hcNh2J3721/PvXNze6oIXyBgI6BsSeRAgGAGJLATgBl2LsjCDDhgJwAz7FyQhRlwwE4AZti5IAsz4ICdAMywc0EWZsABOwGYYeeCbCgz9myse/mH387/M8P4vnx27SvfOsb7efivmbyTr54nV29oP3Di1z9n8jb2v0iubnmt5+jpC9NyGzDjkjHCDEaImsEsiGAG04AZzAJmSBYwQ9JIdM04mSPP1NVefYWyfK1/95R26feLe56af61W6qqJl6xTSr/TP3SB9m5K1Wql5ky8QCnV3FH87Q/aR+Q+c9M82wXpt07+6hL90fdmQ+q6Ky2v4Keadpw4c/7L5xbN10pdM/Gah5XSrxcGzlE3kbt5cWruxAuUUo25Y6ddorPUs/X2G2wXPNR+5Bf/guLOdbdc71gG67/o2ld//Hn0KyL3hSULrrW8S8PL35dGKE/kZpctrLVcUN92uOgSDdP+1hWLtFKTrlmjlDbf9A6XdpNnWpbcOJlYS0tLf3+/FLjaGCvQaolNuj7RNWMCDcwmEgjMYBowg1lgBSpZwAxJAzVD0kAcewKhVqCxp4IBEs6OQ4IAAqgZAWASn4YZiVcgAADMCACT+DTMSLwCAQBgRgCYxKdhRuIVCAAAMwLAJD4NMxKvQACAMGaczNWtModCnRDuJfJ2bKqbO2dW+VjCiuZmR2vn7m0DA6MBdxiY7ntr7QPmwIyfEC7uXO8Zp9Hsq+qEcOejdxlHpWqUWrpROea7wiDls+Tq5Yv8wxj1bYe1S8XhwLFP/of+3S2ecTaYz2byhDDMkB8MzGAaoc3ofeNBzzhPmINDo3+XX6533w7PNfevMkmrGUQlIq8zc8fq5z9xjFcYvFgGkm/NPLWrUBxh2lOMol0zymbUmfcOjl7wiMbtmOLQJ10W6dmkMpp8dtlCrZTe/t3+9oxnnLTpKpwZt6RyzZT+hBmMCWYwC6Jom0Hkr0D3bqq7d84sR6lZSq1o3upo8/Xh0b+rLyCxMIOo1EmeydyRcuq3O9oNM5GMCRJ1M6Tlfty772nP1fNXbSsm7NmEQZTNSK+uqXlEKd12OMQaw38xmMFIY1UzYAZ/sOOR/zMmT9/42If+z5tU9xULM/LZzJPa0bsLpSOd/gr0zvu2fhxqCRrpmrF3U+perZxtHQdHL1SWFb07yDNrNn46ULUYFHEzyk+t/rOI8ajy0Er51uWLQk0pcTBDNztzKnugakWzcnRHCC8o2mbwHqiqH3toLY2UFxx3+vuiqr5NafdQNZugMINnnEjXDJjBH+S0R5E2Y9ppRLpmTDMNmCGBwgymATOYxWWynyFvCHFcCYQ5nxFXFhiXJAAzJA3ETABmMAtEkgDMkDQQMwGYwSwQSQIwQ9JAzARgBrNAJAnADEkDMRMIZQb6dDFAdHCTLGCGpIEObkwDZjAL1AzJAmZIGqgZTANmMIuE1wx0pB/vG4+O9PJ7YnKMmiGZYDZhGjCDWSR8NpEgiAhmSCCoGUwDZjAL1AzJAnECCITaHU8AFwwRZsABOwGYYeeCLMyAA3YCMMPOBVmYAQfsBGCGnQuyMAMO2AnADDsXZGEGHLATCGNG6O7S9lsImw3XJeHth281jpo3W6llzx4vDvlv3r35ttTc8gGMxtwx7dKps1XcU7i+41W8wdQuRf8M5gQzmMVl0j8j0jWDqI/I62hasDL7RXHorzLc7i1pVzuPv993+pykPaUYNYMxRdyMcRk2L07p3HHt0sFXmxpMj2O8vqE/eZBTjmAGo4IZzIIIZjCNWJhB1NfRtGCeo5TTmAszi1R4wIwKCaL4mNGw0nGc2bMfzR077RJVv8bwmcCMmJnRvbnp8Q+KAy7R0Y6mm1dmlWM+D7XQgBkwgwnICGYwjYjPJuWn1gbT899DK3Vvuc3VKqVzx6p/bIUZMTGD90BVY+64P5uc6+tI3+wvRWcrpRpzSrs/VbMJCjNgBhOQEcxgGhGfTXgg0xLBDMYIM5gFnlolC5ghaaBmSBqI408gzPmM+FPBCIlgBiywE4AZdi7Iwgw4YCcAM+xckIUZcMBOAGbYuSALM+CAnUAoM9CnS8JEBzemATOYBTq4SRYwQ9JAzWAaMINZoGZIFjBD0kh0zUBHenSkl98MgTFqhkST6JohQaDv+AQaMIOBoGYwC6xAJQuYIWmgZkgaiGNPINTueOypYIA47QcHggigZgSRSXoeZiTdgKDxw4wgMknPw4ykGxA0fpgRRCbpeZiRdAOCxg8zgsgkPQ8zkm5A0PjDmIEuCZLmpXVJKHVm00Y7q++pqanxz4Asrd+4Vd9n8gXj0ZmL8n3+J0ZHegYUriM9//9pimAGg0TNYBaX1nMnn808ubtLu15ppFIfSqXWdPqlLtQMybjKONo1o9RJnsmkTaEwWOW47ZdjNmEuMINZ4PebSBbRNiOfJVdn2vcXBivziBxb9TFqBjOLlxn57LKFWqna8iH1+jal3UPFYR7t/0UwgwlF24zyOuO5jwqlER7SWJRvzbTjqXUClKr+CjMkLtQMphFtM8bG0ZnJmDe7jOsN/vfUSrSrNYOdLv6YQ0QxMINofA80VTu2A1reBW3rKgpRpkgGNYNBwQxmgadWySIWZsgBXVKMmsH4YAazQM2QLGCGpHFZ1Ax5Q4jjSiDM+Yy4ssC4JAGYIWkgZgIwg1kgkgRghqSBmAnADGaBSBKAGZIGYiYAM5gFIkkAZkgaiJlAKDPQp4sBooObZAEzJA10cGMaMINZoGZIFjBD0kDNYBowg1kkvGagIz060stvhsAYNUOiwWzCNGAGs0j4bCJB4HcVTKCBmsFAUDOYBWqGZIE4AQRC7Y4ngAuGCDPggJ0AzLBzQRZmwAE7AZhh54IszIADdgIww84FWZgBB+wEYIadC7L/ApCVWuaCaQ7cAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "6349820d",
   "metadata": {},
   "source": [
    "## üìù Task 2\n",
    "\n",
    "El objetivo principal de este ejercicio es que simule un MDP que represente un robot que navega por un laberinto de cuadr√≠culas de 3x3 y eval√∫e una pol√≠tica determinada. Por ello considere, a un robot navega por un laberinto de cuadr√≠cula de 3x3. El robot puede moverse en cuatro direcciones: arriba, abajo, izquierda y derecha. El objetivo es navegar desde la posici√≥n inicial hasta la posici√≥n de meta evitando obst√°culos. El robot recibe una recompensa cuando alcanza la meta y una penalizaci√≥n si choca con un obst√°culo.\n",
    "\n",
    "El laberinto es el siguiente:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Donde:\n",
    "\n",
    "‚óè S = punto de inicio\n",
    "\n",
    "‚óè G = punto de meta\n",
    "\n",
    "‚óè X = son obst√°culos\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "‚óè Defina los componentes del MDP:\n",
    "\n",
    "‚óã Estados: S = {0, 1, 2, 3, 4, 5, 6, 7, 8}, donde cada n√∫mero representa una celda del laberinto.\n",
    "\n",
    "‚óã Acciones: A = {arriba, abajo, izquierda, derecha}\n",
    "\n",
    "‚óã Probabilidades de transici√≥n: P(s' | s, a)\n",
    "\n",
    "‚óã Recompensas: R(s, a, s')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ae27d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "effb6a76",
   "metadata": {},
   "source": [
    "Matriz de transici√≥n:\n",
    "\n",
    "‚óã Defina las probabilidades de transici√≥n P como un diccionario donde P[s][a] asigna los siguientes estados s' a sus probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779cacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22251c5d",
   "metadata": {},
   "source": [
    "Funci√≥n de recompensa:\n",
    "\n",
    "‚óã Defina las recompensas R como un diccionario donde R[s][a][s'] da la recompensa por la transici√≥n del estado s al estado s' mediante la acci√≥n a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2c845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71d65d9d",
   "metadata": {},
   "source": [
    "Inicializar funci√≥n de valor:\n",
    "\n",
    "‚óã Inicialice la funci√≥n de valor V para todos los estados en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983635f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36cab64f",
   "metadata": {},
   "source": [
    "Algoritmo de iteraci√≥n de valor:\n",
    "\n",
    "‚óã Implemente el algoritmo de iteraci√≥n de valores para actualizar la funci√≥n de valor V y encontrar la pol√≠tica √≥ptima.\n",
    "\n",
    "‚óã Usa un factor de descuento ùõæ de 0,9.\n",
    "\n",
    "‚óã La iteraci√≥n debe detenerse cuando el cambio m√°ximo en la funci√≥n de valor sea menor que un umbral (por ejemplo, 0,001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941418d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3683a139",
   "metadata": {},
   "source": [
    "Extraiga la pol√≠tica √≥ptima de la iteraci√≥n de valor:\n",
    "\n",
    "‚óã Despu√©s de converger, extraiga la pol√≠tica √≥ptima de la funci√≥n de valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd81f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43c6cf14",
   "metadata": {},
   "source": [
    "Algoritmo de iteraci√≥n de pol√≠ticas:\n",
    "\n",
    "‚óã Implemente el algoritmo de iteraci√≥n de pol√≠ticas para encontrar la pol√≠tica √≥ptima.\n",
    "\n",
    "‚óã Inicialice una pol√≠tica aleatoria.\n",
    "\n",
    "‚óã Evaluaci√≥n de pol√≠ticas: eval√∫e la pol√≠tica actual para encontrar la funci√≥n de valor.\n",
    "\n",
    "‚óã Mejora de la pol√≠tica: actualice la pol√≠tica en funci√≥n de la funci√≥n de valor.\n",
    "\n",
    "‚óã La iteraci√≥n deber√≠a detenerse cuando la pol√≠tica ya no cambie.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
