{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75f95bc",
   "metadata": {},
   "source": [
    "<table style=\"width:100%; border-collapse: collapse;\">\n",
    "  <tr>\n",
    "    <td style=\"width:20%; vertical-align:middle;\">\n",
    "      <img src=\"LogoUVG.png\" width=\"400\"/>\n",
    "    </td>\n",
    "    <td style=\"text-align:left; vertical-align:middle;\">\n",
    "      <h2 style=\"margin-bottom: 0;\">Universidad del Valle de Guatemala - UVG</h2>\n",
    "      <h3 style=\"margin-top: 0;\">Facultad de Ingenier√≠a - Computaci√≥n</h3>\n",
    "      <p style=\"font-size: 16px; margin-bottom: 0; margin-top: -20px\">\n",
    "        <strong>Curso:</strong> CC3104 - Aprendizaje por Refuerzo \n",
    "        <strong>Secci√≥n:</strong> 10\n",
    "      </p>\n",
    "      <p style=\"font-size: 16px; margin: 0;\"><strong>Laboratorio 3:</strong> MDP</p>\n",
    "      <br>\n",
    "      <p style=\"font-size: 15px; margin: 0;\"><strong>Autores:</strong></p>\n",
    "      <ul style=\"margin-top: 5px; padding-left: 20px; font-size: 15px;\">\n",
    "        <li>Diego Alexander Hern√°ndez Silvestre - <strong>21270</strong></li>\n",
    "        <li>Linda In√©s Jim√©nez Vides - <strong>21169</strong></li>\n",
    "        <li>Mario Antonio Guerra Morales - <strong>21008</strong></li>\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3efa3ce",
   "metadata": {},
   "source": [
    "## üìù Task 1\n",
    "Responda a cada de las siguientes preguntas de forma clara y lo m√°s completamente posible.\n",
    "1. ¬øQu√© es Programaci√≥n Din√°mica y c√≥mo se relaciona con RL?\n",
    "\n",
    "- \n",
    "\n",
    "2. Explique en sus propias palabras el algoritmo de Iteraci√≥n de P√≥liza.\n",
    "\n",
    "- \n",
    "\n",
    "3. Explique en sus propias palabras el algoritmo de Iteraci√≥n de Valor.\n",
    "\n",
    "- \n",
    "\n",
    "4. En el laboratorio pasado, vimos que el valor de los premios obtenidos se mantienen constantes, ¬øpor qu√©?"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6349820d",
   "metadata": {},
   "source": [
    "## üìù Task 2\n",
    "\n",
    "El objetivo principal de este ejercicio es que simule un MDP que represente un robot que navega por un laberinto de cuadr√≠culas de 3x3 y eval√∫e una pol√≠tica determinada. Por ello considere, a un robot navega por un laberinto de cuadr√≠cula de 3x3. El robot puede moverse en cuatro direcciones: arriba, abajo, izquierda y derecha. El objetivo es navegar desde la posici√≥n inicial hasta la posici√≥n de meta evitando obst√°culos. El robot recibe una recompensa cuando alcanza la meta y una penalizaci√≥n si choca con un obst√°culo.\n",
    "\n",
    "El laberinto es el siguiente:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Donde:\n",
    "\n",
    "‚óè S = punto de inicio\n",
    "\n",
    "‚óè G = punto de meta\n",
    "\n",
    "‚óè X = son obst√°culos\n",
    "\n",
    "Instrucciones:\n",
    "\n",
    "‚óè Defina los componentes del MDP:\n",
    "\n",
    "‚óã Estados: S = {0, 1, 2, 3, 4, 5, 6, 7, 8}, donde cada n√∫mero representa una celda del laberinto.\n",
    "\n",
    "‚óã Acciones: A = {arriba, abajo, izquierda, derecha}\n",
    "\n",
    "‚óã Probabilidades de transici√≥n: P(s' | s, a)\n",
    "\n",
    "‚óã Recompensas: R(s, a, s')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5ae27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "states = list(range(9)) # Lista de estados\n",
    "actions = ['up', 'down', 'left', 'right'] # Acciones que puede realizar.\n",
    "start_state = 0 # Estado inicial\n",
    "goal_state = 8 # Estado final\n",
    "obstacles = [2, 4] # Obst√°culos\n",
    "\n",
    "def state_to_coords(state):\n",
    "    return (state // 3, state % 3)\n",
    "\n",
    "def coords_to_state(row, col):\n",
    "    return row * 3 + col\n",
    "\n",
    "P = {} # Probabilidades de transici√≥n\n",
    "R = {} # Recompensas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb6a76",
   "metadata": {},
   "source": [
    "Matriz de transici√≥n:\n",
    "\n",
    "‚óã Defina las probabilidades de transici√≥n P como un diccionario donde P[s][a] asigna los siguientes estados s' a sus probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2779cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in states:\n",
    "    if s in obstacles or s == goal_state:\n",
    "        continue\n",
    "    P[s] = {}\n",
    "    row, col = state_to_coords(s)\n",
    "\n",
    "    for a in actions:\n",
    "        P[s][a] = {}\n",
    "        next_row, next_col = row, col\n",
    "\n",
    "        if a == 'up': next_row -= 1\n",
    "        elif a == 'down': next_row += 1\n",
    "        elif a == 'left': next_col -= 1\n",
    "        elif a == 'right': next_col += 1\n",
    "\n",
    "        if 0 <= next_row < 3 and 0 <= next_col < 3:\n",
    "            s_prime = coords_to_state(next_row, next_col)\n",
    "            if s_prime in obstacles:\n",
    "                s_prime = s  # rebota\n",
    "        else:\n",
    "            s_prime = s  # rebota\n",
    "\n",
    "        P[s][a][s_prime] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22251c5d",
   "metadata": {},
   "source": [
    "Funci√≥n de recompensa:\n",
    "\n",
    "‚óã Defina las recompensas R como un diccionario donde R[s][a][s'] da la recompensa por la transici√≥n del estado s al estado s' mediante la acci√≥n a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e2c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in states:\n",
    "    if s in obstacles or s == goal_state:\n",
    "        continue\n",
    "    R[s] = {}\n",
    "    row, col = state_to_coords(s)\n",
    "\n",
    "    for a in actions:\n",
    "        R[s][a] = {}\n",
    "\n",
    "        next_row, next_col = row, col\n",
    "        if a == 'up': next_row -= 1\n",
    "        elif a == 'down': next_row += 1\n",
    "        elif a == 'left': next_col -= 1\n",
    "        elif a == 'right': next_col += 1\n",
    "\n",
    "        if 0 <= next_row < 3 and 0 <= next_col < 3:\n",
    "            s_prime = coords_to_state(next_row, next_col)\n",
    "            if s_prime in obstacles:\n",
    "                s_prime = s\n",
    "                reward = -1\n",
    "            elif s_prime == goal_state:\n",
    "                reward = 10\n",
    "            else:\n",
    "                reward = -0.1\n",
    "        else:\n",
    "            s_prime = s\n",
    "            reward = -1\n",
    "\n",
    "        R[s][a][s_prime] = reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d65d9d",
   "metadata": {},
   "source": [
    "Inicializar funci√≥n de valor:\n",
    "\n",
    "‚óã Inicialice la funci√≥n de valor V para todos los estados en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2983635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "V = np.zeros(len(states))\n",
    "print(V.reshape((3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cab64f",
   "metadata": {},
   "source": [
    "Algoritmo de iteraci√≥n de valor:\n",
    "\n",
    "‚óã Implemente el algoritmo de iteraci√≥n de valores para actualizar la funci√≥n de valor V y encontrar la pol√≠tica √≥ptima.\n",
    "\n",
    "‚óã Usa un factor de descuento ùõæ de 0,9.\n",
    "\n",
    "‚óã La iteraci√≥n debe detenerse cuando el cambio m√°ximo en la funci√≥n de valor sea menor que un umbral (por ejemplo, 0,001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "941418d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.9\n",
    "theta = 0.001\n",
    "\n",
    "def value_iteration():\n",
    "    V = np.zeros(len(states))\n",
    "    policy = np.array([\"\"] * len(states))\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for s in states:\n",
    "            if s in obstacles or s == goal_state:\n",
    "                continue\n",
    "            v = V[s]\n",
    "            max_value = float('-inf')\n",
    "            best_action = None\n",
    "            for a in actions:\n",
    "                total = 0\n",
    "                for s_prime in P[s][a]:\n",
    "                    total += P[s][a][s_prime] * (R[s][a][s_prime] + gamma * V[s_prime])\n",
    "                if total > max_value:\n",
    "                    max_value = total\n",
    "                    best_action = a\n",
    "            V[s] = max_value\n",
    "            policy[s] = best_action\n",
    "            delta = max(delta, abs(v - V[s]))\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3683a139",
   "metadata": {},
   "source": [
    "Extraiga la pol√≠tica √≥ptima de la iteraci√≥n de valor:\n",
    "\n",
    "‚óã Despu√©s de converger, extraiga la pol√≠tica √≥ptima de la funci√≥n de valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd81f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Funci√≥n de valor √≥ptima (VI):\n",
      "[[ 7.019   6.2171  0.    ]\n",
      " [ 7.91    0.     10.    ]\n",
      " [ 8.9    10.      0.    ]]\n",
      "\n",
      "üî∏ Pol√≠tica √≥ptima (VI):\n",
      "[['d' 'l' '']\n",
      " ['d' '' 'd']\n",
      " ['r' 'r' '']]\n"
     ]
    }
   ],
   "source": [
    "V_vi, policy_vi = value_iteration()\n",
    "\n",
    "print(\"Funci√≥n de valor √≥ptima (VI):\")\n",
    "print(V_vi.reshape((3, 3)))\n",
    "\n",
    "print(\"Pol√≠tica √≥ptima (VI):\")\n",
    "print(policy_vi.reshape((3, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6cf14",
   "metadata": {},
   "source": [
    "Algoritmo de iteraci√≥n de pol√≠ticas:\n",
    "\n",
    "‚óã Implemente el algoritmo de iteraci√≥n de pol√≠ticas para encontrar la pol√≠tica √≥ptima.\n",
    "\n",
    "‚óã Inicialice una pol√≠tica aleatoria.\n",
    "\n",
    "‚óã Evaluaci√≥n de pol√≠ticas: eval√∫e la pol√≠tica actual para encontrar la funci√≥n de valor.\n",
    "\n",
    "‚óã Mejora de la pol√≠tica: actualice la pol√≠tica en funci√≥n de la funci√≥n de valor.\n",
    "\n",
    "‚óã La iteraci√≥n deber√≠a detenerse cuando la pol√≠tica ya no cambie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cec2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√≥digo aqu√≠"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
